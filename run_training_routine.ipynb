{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_available:  True\n",
      "device_count:  1\n",
      "current_device:  0\n",
      "current_device:  <torch.cuda.device object at 0x0000019F1F4E6940>\n",
      "get_device_name:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use this to run the train.py routine\n",
    "\"\"\"\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import presets\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.models.detection\n",
    "import torchvision.models.detection.mask_rcnn\n",
    "import utils\n",
    "from coco_utils import get_coco, get_coco_kp\n",
    "from engine import evaluate, train_one_epoch\n",
    "from group_by_aspect_ratio import create_aspect_ratio_groups, GroupedBatchSampler\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from transforms import SimpleCopyPaste\n",
    "\n",
    "\n",
    "print('is_available: ', torch.cuda.is_available())\n",
    "print('device_count: ', torch.cuda.device_count())\n",
    "print('current_device: ', torch.cuda.current_device())\n",
    "print('current_device: ', torch.cuda.device(0))\n",
    "print('get_device_name: ', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def copypaste_collate_fn(batch):\n",
    "    copypaste = SimpleCopyPaste(blending=True, resize_interpolation=InterpolationMode.BILINEAR)\n",
    "    return copypaste(*utils.collate_fn(batch))\n",
    "\n",
    "\n",
    "def get_dataset(name, image_set, transform, data_path):\n",
    "    paths = {\"coco\": (data_path, get_coco, 91), \"coco_kp\": (data_path, get_coco_kp, 2)}\n",
    "    p, ds_fn, num_classes = paths[name]\n",
    "\n",
    "    ds = ds_fn(p, image_set=image_set, transforms=transform)\n",
    "    return ds, num_classes\n",
    "\n",
    "\n",
    "def get_transform(train, args):\n",
    "    if train:\n",
    "        return presets.DetectionPresetTrain(data_augmentation=args.data_augmentation)\n",
    "    elif args.weights and args.test_only:\n",
    "        weights = torchvision.models.get_weight(args.weights)\n",
    "        trans = weights.transforms()\n",
    "        return lambda img, target: (trans(img), target)\n",
    "    else:\n",
    "        return presets.DetectionPresetEval()\n",
    "\n",
    "\n",
    "def get_args_parser(add_help=True):\n",
    "\n",
    "    import argparse\n",
    "\n",
    "    \n",
    "#'--nproc_per_node = 0 --data-path = C:\\Users\\endle\\Desktop\\pytorch-retinanet\\data\n",
    "# --dataset coco \n",
    "# --model retinanet_resnet50_fpn \n",
    "# --epochs 26 \n",
    "# --lr-steps 16 22 \n",
    "# --aspect-ratio-group-factor 3 \n",
    "# --lr 0.001 \n",
    "# --weights-backbone ResNet50_Weights.IMAGENET1K_V1 train.py\\\n",
    "\n",
    "    output_dir_path = r'C:\\Users\\endle\\Desktop\\pytorch-retinanet\\outputdir'\n",
    "    data_dir_path = r\"C:\\Users\\endle\\Desktop\\pytorch-retinanet\\data\"\n",
    "    dataset_type = 'coco'\n",
    "    model = \"retinanet_resnet50_fpn\"\n",
    "    device_type = \"cuda\"\n",
    "    batch_size = 8\n",
    "    epochs = 26\n",
    "    workers = 1\n",
    "    optimizer = \"sgd\"\n",
    "    norm_weight_decay = 0.9\n",
    "    momentum = 0.9\n",
    "    lr = 0.02\n",
    "    weight_decay = 1e-4\n",
    "    lr_step_size = 8\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch Detection Training\", add_help=add_help)\n",
    "\n",
    "    parser.add_argument(\"--data-path\", default=data_dir_path, type=str, help=\"dataset path\")\n",
    "    parser.add_argument(\"--dataset\", default=dataset_type, type=str, help=\"dataset name\")\n",
    "    parser.add_argument(\"--model\", default=model, type=str, help=\"model name\")\n",
    "    parser.add_argument(\"--device\", default=device_type, type=str, help=\"device (Use cuda or cpu Default: cuda)\")\n",
    "    parser.add_argument(\n",
    "        \"-b\", \"--batch-size\", default=batch_size, type=int, help=\"images per gpu, the total batch size is $NGPU x batch_size\"\n",
    "    )\n",
    "    parser.add_argument(\"--epochs\", default=epochs, type=int, metavar=\"N\", help=\"number of total epochs to run\")\n",
    "    parser.add_argument(\n",
    "        \"-j\", \"--workers\", default=workers, type=int, metavar=\"N\", help=\"number of data loading workers (default: 4)\"\n",
    "    )\n",
    "    parser.add_argument(\"--opt\", default=optimizer, type=str, help=\"optimizer\")\n",
    "    parser.add_argument(\n",
    "        \"--lr\",\n",
    "        default=lr,\n",
    "        type=float,\n",
    "        help=\"initial learning rate, 0.02 is the default value for training on 8 gpus and 2 images_per_gpu\",\n",
    "    )\n",
    "    parser.add_argument(\"--momentum\", default=momentum, type=float, metavar=\"M\", help=\"momentum\")\n",
    "    parser.add_argument(\n",
    "        \"--wd\",\n",
    "        \"--weight-decay\",\n",
    "        default=weight_decay,\n",
    "        type=float,\n",
    "        metavar=\"W\",\n",
    "        help=\"weight decay (default: 1e-4)\",\n",
    "        dest=\"weight_decay\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--norm-weight-decay\",\n",
    "        default=norm_weight_decay,\n",
    "        type=float,\n",
    "        help=\"weight decay for Normalization layers (default: None, same value as --wd)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr-scheduler\", default=\"multisteplr\", type=str, help=\"name of lr scheduler (default: multisteplr)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr-step-size\", default=lr_step_size, type=int, help=\"decrease lr every step-size epochs (multisteplr scheduler only)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr-steps\",\n",
    "        default=[16, 22],\n",
    "        nargs=\"+\",\n",
    "        type=int,\n",
    "        help=\"decrease lr every step-size epochs (multisteplr scheduler only)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr-gamma\", default=0.1, type=float, help=\"decrease lr by a factor of lr-gamma (multisteplr scheduler only)\"\n",
    "    )\n",
    "    parser.add_argument(\"--print-freq\", default=20, type=int, help=\"print frequency\")\n",
    "    parser.add_argument(\"--output_dir\", default=output_dir_path, type=str, help=\"path to save outputs\")\n",
    "    parser.add_argument(\"--resume\", default=output_dir_path, type=str, help=\"path of checkpoint\")\n",
    "    parser.add_argument(\"--start_epoch\", default=0, type=int, help=\"start epoch\")\n",
    "    parser.add_argument(\"--aspect-ratio-group-factor\", default=3, type=int)\n",
    "    parser.add_argument(\"--rpn-score-thresh\", default=None, type=float, help=\"rpn score threshold for faster-rcnn\")\n",
    "    parser.add_argument(\n",
    "        \"--trainable-backbone-layers\", default=None, type=int, help=\"number of trainable layers of backbone\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data-augmentation\", default=\"hflip\", type=str, help=\"data augmentation policy (default: hflip)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sync-bn\",\n",
    "        dest=\"sync_bn\",\n",
    "        help=\"Use sync batch norm\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--test-only\",\n",
    "        dest=\"test_only\",\n",
    "        help=\"Only test the model\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--use-deterministic-algorithms\", action=\"store_true\", help=\"Forces the use of deterministic algorithms only.\"\n",
    "    )\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument(\"--world-size\", default=1, type=int, help=\"number of distributed processes\")\n",
    "    parser.add_argument(\"--dist-url\", default=\"env://\", type=str, help=\"url used to set up distributed training\")\n",
    "    parser.add_argument(\"--weights\", default=None, type=str, help=\"the weights enum name to load\")\n",
    "    parser.add_argument(\"--weights-backbone\", default='ResNet50_Weights.IMAGENET1K_V1', type=str, help=\"the backbone weights enum name to load\")\n",
    "\n",
    "    # Mixed precision training parameters\n",
    "    parser.add_argument(\"--amp\", default=True, action=\"store_true\", help=\"Use torch.cuda.amp for mixed precision training\")\n",
    "\n",
    "    # Use CopyPaste augmentation training parameter\n",
    "    parser.add_argument(\n",
    "        \"--use-copypaste\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Use CopyPaste data augmentation. Works only with data-augmentation='lsj'.\",\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    #if args.output_dir:\n",
    "    output_dir_path = r'C:\\Users\\endle\\Desktop\\pytorch-retinanet\\outputdir'\n",
    "\n",
    "    utils.mkdir(output_dir_path)\n",
    "\n",
    "    utils.init_distributed_mode(args)\n",
    "    print('what is in args: ,', args)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    #if args.use_deterministic_algorithms:\n",
    "    \n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    # Data loading code\n",
    "    print(\"Loading data\")\n",
    "\n",
    "    dataset, num_classes = get_dataset(args.dataset, \"train\", get_transform(True, args), args.data_path)\n",
    "    dataset_test, _ = get_dataset(args.dataset, \"val\", get_transform(False, args), args.data_path)\n",
    "\n",
    "    print(\"Creating data loaders\")\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "        test_sampler = torch.utils.data.distributed.DistributedSampler(dataset_test, shuffle=False)\n",
    "    else:\n",
    "        train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "        test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "    if args.aspect_ratio_group_factor >= 0:\n",
    "        group_ids = create_aspect_ratio_groups(dataset, k=args.aspect_ratio_group_factor)\n",
    "        train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, args.batch_size)\n",
    "    else:\n",
    "        train_batch_sampler = torch.utils.data.BatchSampler(train_sampler, args.batch_size, drop_last=True)\n",
    "\n",
    "    train_collate_fn = utils.collate_fn\n",
    "    if args.use_copypaste:\n",
    "        if args.data_augmentation != \"lsj\":\n",
    "            raise RuntimeError(\"SimpleCopyPaste algorithm currently only supports the 'lsj' data augmentation policies\")\n",
    "\n",
    "        train_collate_fn = copypaste_collate_fn\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_sampler=train_batch_sampler, num_workers=args.workers, collate_fn=train_collate_fn\n",
    "    )\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, sampler=test_sampler, num_workers=args.workers, collate_fn=utils.collate_fn\n",
    "    )\n",
    "\n",
    "    print(\"Creating model\")\n",
    "    kwargs = {\"trainable_backbone_layers\": args.trainable_backbone_layers}\n",
    "    if args.data_augmentation in [\"multiscale\", \"lsj\"]:\n",
    "        kwargs[\"_skip_resize\"] = True\n",
    "    if \"rcnn\" in args.model:\n",
    "        if args.rpn_score_thresh is not None:\n",
    "            kwargs[\"rpn_score_thresh\"] = args.rpn_score_thresh\n",
    "    model = torchvision.models.get_model(\n",
    "        args.model, weights=args.weights, weights_backbone=args.weights_backbone, num_classes=num_classes, **kwargs\n",
    "    )\n",
    "    model.to(device)\n",
    "    if args.distributed and args.sync_bn:\n",
    "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "\n",
    "    model_without_ddp = model\n",
    "    if args.distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        model_without_ddp = model.module\n",
    "\n",
    "    if args.norm_weight_decay is None:\n",
    "        parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        param_groups = torchvision.ops._utils.split_normalization_params(model)\n",
    "        wd_groups = [args.norm_weight_decay, args.weight_decay]\n",
    "        parameters = [{\"params\": p, \"weight_decay\": w} for p, w in zip(param_groups, wd_groups) if p]\n",
    "\n",
    "    opt_name = args.opt.lower()\n",
    "    if opt_name.startswith(\"sgd\"):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            parameters,\n",
    "            lr=args.lr,\n",
    "            momentum=args.momentum,\n",
    "            weight_decay=args.weight_decay,\n",
    "            nesterov=\"nesterov\" in opt_name,\n",
    "        )\n",
    "    elif opt_name == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(parameters, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Invalid optimizer {args.opt}. Only SGD and AdamW are supported.\")\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler() if args.amp else None\n",
    "\n",
    "    args.lr_scheduler = args.lr_scheduler.lower()\n",
    "    if args.lr_scheduler == \"multisteplr\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.lr_steps, gamma=args.lr_gamma)\n",
    "    elif args.lr_scheduler == \"cosineannealinglr\":\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Invalid lr scheduler '{args.lr_scheduler}'. Only MultiStepLR and CosineAnnealingLR are supported.\"\n",
    "        )\n",
    "    \n",
    "    print('what is argsresume: ', args.resume)\n",
    "\n",
    "    # if args.resume:\n",
    "    #     checkpoint = torch.load(args.resume, map_location=\"cpu\")\n",
    "    #     model_without_ddp.load_state_dict(checkpoint[\"model\"])\n",
    "    #     optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    #     lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
    "    #     args.start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    #     if args.amp:\n",
    "    #         scaler.load_state_dict(checkpoint[\"scaler\"])\n",
    "\n",
    "    if args.test_only:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "        return\n",
    "\n",
    "    print(\"Start training\")\n",
    "    start_time = time.time()\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "\n",
    "        #print('look at data_loader: ', data_loader) # <torch.utils.data.dataloader.DataLoader object at 0x00000188DE551940>\n",
    "        #print('len of dataloader: ', len(data_loader))\n",
    "\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, args.print_freq, scaler)\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        if args.output_dir:\n",
    "            checkpoint = {\n",
    "                \"model\": model_without_ddp.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "                \"args\": args,\n",
    "                \"epoch\": epoch,\n",
    "            }\n",
    "            if args.amp:\n",
    "                checkpoint[\"scaler\"] = scaler.state_dict()\n",
    "            utils.save_on_master(checkpoint, os.path.join(args.output_dir, f\"model_{epoch}.pth\"))\n",
    "            utils.save_on_master(checkpoint, os.path.join(args.output_dir, \"checkpoint.pth\"))\n",
    "\n",
    "        # evaluate after every epoch\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(f\"Training time {total_time_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(amp=True, aspect_ratio_group_factor=3, batch_size=8, data_augmentation='hflip', data_path='C:\\\\Users\\\\endle\\\\Desktop\\\\pytorch-retinanet\\\\data', dataset='coco', device='cuda', dist_url='env://', epochs=26, lr=0.02, lr_gamma=0.1, lr_scheduler='multisteplr', lr_step_size=8, lr_steps=[16, 22], model='retinanet_resnet50_fpn', momentum=0.9, norm_weight_decay=0.9, opt='sgd', output_dir='C:\\\\Users\\\\endle\\\\Desktop\\\\pytorch-retinanet\\\\outputdir', print_freq=20, resume='C:\\\\Users\\\\endle\\\\Desktop\\\\pytorch-retinanet\\\\outputdir', rpn_score_thresh=None, start_epoch=0, sync_bn=False, test_only=False, trainable_backbone_layers=None, use_copypaste=False, use_deterministic_algorithms=False, weight_decay=0.0001, weights=None, weights_backbone='ResNet50_Weights.IMAGENET1K_V1', workers=1, world_size=1)\n",
      "Not using distributed mode\n",
      "what is in args: , Namespace(amp=True, aspect_ratio_group_factor=3, batch_size=8, data_augmentation='hflip', data_path='C:\\\\Users\\\\endle\\\\Desktop\\\\pytorch-retinanet\\\\data', dataset='coco', device='cuda', dist_url='env://', distributed=False, epochs=26, lr=0.02, lr_gamma=0.1, lr_scheduler='multisteplr', lr_step_size=8, lr_steps=[16, 22], model='retinanet_resnet50_fpn', momentum=0.9, norm_weight_decay=0.9, opt='sgd', output_dir='C:\\\\Users\\\\endle\\\\Desktop\\\\pytorch-retinanet\\\\outputdir', print_freq=20, resume='C:\\\\Users\\\\endle\\\\Desktop\\\\pytorch-retinanet\\\\outputdir', rpn_score_thresh=None, start_epoch=0, sync_bn=False, test_only=False, trainable_backbone_layers=None, use_copypaste=False, use_deterministic_algorithms=False, weight_decay=0.0001, weights=None, weights_backbone='ResNet50_Weights.IMAGENET1K_V1', workers=1, world_size=1)\n",
      "Loading data\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Creating data loaders\n",
      "Using [0, 0.5, 0.6299605249474366, 0.7937005259840997, 1.0, 1.2599210498948732, 1.5874010519681994, 2.0, inf] as bins for aspect ratio quantization\n",
      "Count of instances per bin: [  3  41 326]\n",
      "Creating model\n",
      "what is argsresume:  C:\\Users\\endle\\Desktop\\pytorch-retinanet\\outputdir\n",
      "Start training\n",
      "Epoch: [0]  [ 0/46]  eta: 0:04:32  lr: 0.000464  loss: 2.1361 (2.1361)  classification: 1.4663 (1.4663)  bbox_regression: 0.6698 (0.6698)  time: 5.9138  data: 2.2878  max mem: 10893\n",
      "Epoch: [0]  [20/46]  eta: 0:00:23  lr: 0.009344  loss: 2.1109 (2.1148)  classification: 1.4668 (1.4634)  bbox_regression: 0.6515 (0.6514)  time: 0.6443  data: 0.0065  max mem: 11185\n",
      "Epoch: [0]  [40/46]  eta: 0:00:04  lr: 0.018224  loss: 1.9970 (2.0572)  classification: 1.4155 (1.4328)  bbox_regression: 0.5967 (0.6244)  time: 0.6047  data: 0.0075  max mem: 11185\n",
      "Epoch: [0]  [45/46]  eta: 0:00:00  lr: 0.020000  loss: 1.9584 (2.0430)  classification: 1.4093 (1.4251)  bbox_regression: 0.5788 (0.6180)  time: 0.6069  data: 0.0077  max mem: 11185\n",
      "Epoch: [0] Total time: 0:00:34 (0.7424 s / it)\n",
      "Test:  [  0/529]  eta: 0:21:09  model_time: 0.1724 (0.1724)  evaluator_time: 0.0000 (0.0000)  time: 2.3992  data: 2.2256  max mem: 11185\n",
      "Test:  [100/529]  eta: 0:00:33  model_time: 0.0503 (0.0530)  evaluator_time: 0.0000 (0.0004)  time: 0.0525  data: 0.0008  max mem: 11185\n",
      "Test:  [200/529]  eta: 0:00:21  model_time: 0.0483 (0.0513)  evaluator_time: 0.0000 (0.0004)  time: 0.0517  data: 0.0008  max mem: 11185\n",
      "Test:  [300/529]  eta: 0:00:13  model_time: 0.0480 (0.0505)  evaluator_time: 0.0010 (0.0005)  time: 0.0523  data: 0.0009  max mem: 11185\n",
      "Test:  [400/529]  eta: 0:00:07  model_time: 0.0457 (0.0500)  evaluator_time: 0.0000 (0.0004)  time: 0.0510  data: 0.0010  max mem: 11185\n",
      "Test:  [500/529]  eta: 0:00:01  model_time: 0.0481 (0.0497)  evaluator_time: 0.0010 (0.0004)  time: 0.0497  data: 0.0007  max mem: 11185\n",
      "Test:  [528/529]  eta: 0:00:00  model_time: 0.0485 (0.0496)  evaluator_time: 0.0000 (0.0004)  time: 0.0516  data: 0.0007  max mem: 11185\n",
      "Test: Total time: 0:00:30 (0.0570 s / it)\n",
      "Averaged stats: model_time: 0.0485 (0.0496)  evaluator_time: 0.0000 (0.0004)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [1]  [ 0/46]  eta: 0:02:21  lr: 0.020000  loss: 1.9537 (1.9537)  classification: 1.4024 (1.4024)  bbox_regression: 0.5514 (0.5514)  time: 3.0765  data: 2.2625  max mem: 11185\n",
      "Epoch: [1]  [20/46]  eta: 0:00:19  lr: 0.020000  loss: 1.9593 (1.9417)  classification: 1.4137 (1.3996)  bbox_regression: 0.5362 (0.5421)  time: 0.6224  data: 0.0084  max mem: 11186\n",
      "Epoch: [1]  [40/46]  eta: 0:00:04  lr: 0.020000  loss: 1.9443 (1.9561)  classification: 1.3744 (1.3829)  bbox_regression: 0.5779 (0.5732)  time: 0.6589  data: 0.0087  max mem: 11186\n",
      "Epoch: [1]  [45/46]  eta: 0:00:00  lr: 0.020000  loss: 1.9893 (1.9586)  classification: 1.4032 (1.3835)  bbox_regression: 0.5937 (0.5751)  time: 0.6591  data: 0.0078  max mem: 11186\n",
      "Epoch: [1] Total time: 0:00:32 (0.7022 s / it)\n",
      "Test:  [  0/529]  eta: 0:21:45  model_time: 0.1262 (0.1262)  evaluator_time: 0.0000 (0.0000)  time: 2.4681  data: 2.3409  max mem: 11186\n",
      "Test:  [100/529]  eta: 0:00:33  model_time: 0.0534 (0.0521)  evaluator_time: 0.0000 (0.0004)  time: 0.0554  data: 0.0008  max mem: 11186\n",
      "Test:  [200/529]  eta: 0:00:22  model_time: 0.0541 (0.0528)  evaluator_time: 0.0000 (0.0004)  time: 0.0571  data: 0.0009  max mem: 11186\n",
      "Test:  [300/529]  eta: 0:00:14  model_time: 0.0526 (0.0531)  evaluator_time: 0.0000 (0.0005)  time: 0.0540  data: 0.0009  max mem: 11186\n",
      "Test:  [400/529]  eta: 0:00:07  model_time: 0.0516 (0.0530)  evaluator_time: 0.0000 (0.0005)  time: 0.0529  data: 0.0009  max mem: 11186\n",
      "Test:  [500/529]  eta: 0:00:01  model_time: 0.0546 (0.0532)  evaluator_time: 0.0000 (0.0005)  time: 0.0559  data: 0.0010  max mem: 11186\n",
      "Test:  [528/529]  eta: 0:00:00  model_time: 0.0541 (0.0532)  evaluator_time: 0.0010 (0.0005)  time: 0.0575  data: 0.0009  max mem: 11186\n",
      "Test: Total time: 0:00:32 (0.0608 s / it)\n",
      "Averaged stats: model_time: 0.0541 (0.0532)  evaluator_time: 0.0010 (0.0005)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [2]  [ 0/46]  eta: 0:02:28  lr: 0.020000  loss: 1.9477 (1.9477)  classification: 1.4313 (1.4313)  bbox_regression: 0.5165 (0.5165)  time: 3.2329  data: 2.3872  max mem: 11186\n",
      "Loss is nan, stopping training\n",
      "{'classification': tensor(nan, device='cuda:0', grad_fn=<DivBackward0>), 'bbox_regression': tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\endle\\miniconda3\\envs\\pytorch-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# run it\n",
    "\n",
    "#'--nproc_per_node = 0 --data-path = C:\\Users\\endle\\Desktop\\pytorch-retinanet\\data\n",
    "# --dataset coco \n",
    "# --model retinanet_resnet50_fpn \n",
    "# --epochs 26 \n",
    "# --lr-steps 16 22 \n",
    "# --aspect-ratio-group-factor 3 \n",
    "# --lr 0.001 \n",
    "# --weights-backbone ResNet50_Weights.IMAGENET1K_V1 train.py\\\n",
    "\n",
    "#ya = ['--nproc_per_node', '1']\n",
    "yo = ['--weights-backbone', 'ResNet50_Weights.IMAGENET1K_V1']\n",
    "args = get_args_parser().parse_args(yo)\n",
    "\n",
    "#args.add_argument(\"--device\", default=\"cuda\")\n",
    "print(args)\n",
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
